1、单机安装hadoop   http://blog.csdn.net/zhenzhendeblog/article/details/51602903
	
	（1）、配置ip、主机名
		>查看主机名相关设置：hostnameclt
		>只查看静态、瞬态或灵活主机名：hostnameclt --static\hostname --transient\hostnameclt --pretty
		>同时修改三个主机名：静态、瞬态和灵活主机名:hostnameclt set-hostname huxinxing
		>就像上面展示的那样，在修改静态/瞬态主机名时，任何特殊字符或者空白字符会被移除，而提供的参数中的任何大写字母会自动化转化为小写。一旦修改了静态主机名，/etc/hostname将被自动更新。然而,/etc/hosts不会更新以保存所修改的，所以你每次在修改主机名后一定要手动更新/etc/hosts，之后在重启CentOS。否则系统再启动时会很慢。
		>手动更新/etc/hosts: 192.168.2.110 huxinxing mapleleaf。
		>之后重启CentOS7
	（2）、安装jdk,并设置环境变量
	（3）、下载hadoop,并设置hadoop环境变量
	（4）、修改4个配置文件
	（5）、格式化hdfs
		>hadoop namenode -format
	（6）、启动hadoop
		>./sbin/start-all.sh
	（7）、查看hadoop运行情况
	 	>jps如果存在
		ResourceManager
		NameNode
		NodeManager
		SecondaryNameNode
		DataNode
		Jps
		则说明运行成功
	（8）、centOS关闭防火墙
		systemctl stop firewalld.service #停止firewall
		systemctl disable firewalld.service #禁止firewall开机启动
		firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）



2、hadoop安装教程_单机/伪分布式配置_CentOs6.4/Hadoop http://www.powerxing.com/install-hadoop-in-centos/
	（1）、安装SSH、配置SSH无密码登陆
		>检验SSH：rpm -qa|grep ssh   若已经安装则不需要再次安装
		>通过yum安装ssh:sudo yum install openssh-clients
		  sudo yum install openssh-server
		>执行命令测试ssh是否可用:ssh localhost
		>使用ssh-keygen生成密钥，并将密钥加入到授权中；
			cd ~/.ssh/
			ssh-keygen -t rsa
			cat id_ras.pub >> authorized_keys
			chmod 600 ./authorized_keys
	（2）、伪分布式文件配置
		>core-site.xml、hdfs-site.xml
		<configuration>
		    <property>
		    	<name>hadoop.tmp.dir</name>
			<value>file:/usr/local/hadoop/tmp</value>
			<description>Abase for other temporary directories.</description>
		    </property>
		    <property>
		    	<name>fs.defaultFS</name>
			<value>hdfs://localhost:9000</value>
		    </property>
		</configuration>
		<configuration>
		    <property>
		    	<name>dfs.replication</name>
			<value>1</value>
		    </property>
	            <property>
		    	<name>dfs.namenode.name.dir</name>
			<value>file:/usr/local/hadoop/tmp/dfs/name</value>
		    </property>
		    <property>
			<name>dfs.datanode.data.dir</name>						
			<value>file:/usr/local/hadoop/tmp/dfs/data</value>
		    </property>									
		</configuration>
		>hdfs的WEBUI界面地址为 http://localhost:50070
		>启动yarn,配置文件mapred-site.xml
		<configuration>
		    <property>
		    	<name>mapreduce.framework.name</name>
			<value>yarn</value>
		    </property>
		</configuration>
		配置yarn-site.xml
		<configuration>
		    <property>
		    	<name>yarn.nodemanager.aux-services</name>
			<value>mapreduce_shuffle</value>
		    </property>
	        </configuration>
		yarn的界面地址为：http://localhost:8088/cluster


3、hadoop学习路线   http://blog.csdn.net/u012453843/article/category/6887358/3


4、hadoop三个文件配置的参数说明  http://blog.csdn.net/yangjl38/article/details/7583374


5、hadoop配置文件详解、安装及相关操作   http://www.360doc.com/content/14/0117/16/834950_345989344.shtml


6、zookeeper单机伪分布式集成配置   http://blog.csdn.net/tanyujing/article/details/8504481


7、伪分布式集群环境hadoop、hbase、zookeeper搭建   http://blog.csdn.net/baolibin528/article/details/43768867


8、Hbase配置详解   http://www.cnblogs.com/viviman/archive/2013/03/21/2973539.html


9、hadoop集群安装  http://www.linuxidc.com/Linux/2017-03/142051.htm
