1、Hbase安装配置之伪分布式模式   http://blog.csdn.net/pdw2009/article/details/21261417

2、HBase安装配置（整合到hadoop）  http://blog.csdn.net/hguisu/article/details/7244413/

3、伪分布式集群环境hadoop、hbase、zookeeper搭建   http://blog.csdn.net/baolibin528/article/details/43768867

	（1）、配置hbase-env.sh:export JAVA_HOME=/usr/local/jdk;export HBASE_MANAGES_ZK=true
	（2）、修改hbase-site.xml
		<property>  
	      		<name>hbase.rootdir</name>  
	            	<value>hdfs://m:9000/hbase</value>  
		</property>  
		<property>  
			<name>hbase.cluster.distributed</name>  
			<value>true</value>  
		</property>  
		<property>  
			<name>hbase.zookeeper.quorum</name>  
			<value>m</value>  
		</property>  
		<property>  
			<name>dfs.replication</name>  
			<value>1</value>  
		</property>


4、zookeeper安装和配置（单机模式、伪集群方式、集群模式）  http://coolxing.iteye.com/blog/1871009

	伪集群方式：
	（1）、将zookeeper拷贝至3分。zookerrper0、zookeeper1、zookeeper2
	（2）、更改zook.cfg
		tickTime=2000    
		initLimit=5    
		syncLimit=2    
		dataDir=/Users/apple/zookeeper0/data    
		dataLogDir=/Users/apple/zookeeper0/logs    
		clientPort=2181  
		server.0=127.0.0.1:8880:7770    
		server.1=127.0.0.1:8881:7771    
		server.2=127.0.0.1:8882:7772
		注：另外两个需要修改dataDir、clientPort、dataLogDir
	（3）、在之前设置的dataDir中新建myid文件, 写入一个数字, 该数字表示这是第几号server. 该数字必须和zoo.cfg文件中的server.X中的X一一对应./Users/apple/zookeeper0/data/myid文件中写入0, /Users/apple/zookeeper1/data/myid文件中写入1, /Users/apple/zookeeper2/data/myid文件中写入2.
	（4）、启动zookeeper: zkService.sh start



4、Hbase简介  https://baike.baidu.com/item/HBase/7670213?fr=aladdin

	（1）、结构介绍
	（2）、模型
		A：逻辑模型，主要从用户角度考虑，如何使用hbase
		B：物理模型，主要从实现hbase角度来讨论
	（3）、访问接口
		A：Native Java API，最常规和高效的访问方式，适合hadoop MapReduce Job并行批处理Hbase表数据
		B：HBase Shell,HBase的命令行工具，最简单的接口，适合Hbase管理使用
		C：Thrift Gateway，利用Thrift序列化技术，支持c++、PHP、Python等多种语言，适合其他异构系统在线访问HBase表数据
		D：REST Gateway，支持Rest风格Http API访问HBase，解除了语言的限制
		E：Pig,可以使用Pig Latin流式编程语言来操作HBase中的数据，和Hive类似，本质最终也是编译成MapReduce Job来处理HBase表数据，适合做数据统计
		F：Hive，当前Hive的Release版本尚没有加入对HBase的支持，但在下一个版本Hive0.7.0中将会支持HBase，可以使用类似SQL语言来访问HBase
	（4）Table&Region
		当Table随着记录数不断增加变大后，会逐渐分裂成多份splits,成为regions，一个region由[startkey,endkey]表示，不同的region会被Master分配给相应的RegionServer进行管理
	（5）HBase系统架构
		ClientHBase Client使用HBase的RPC机制与HMaster和HRegionServer进行通信，对于管理类操作，Client与HMaster进行RPC，对于数据读写类操作，CLient和HRegionServer进行RPC
		A：zookeeper；zookeeper Quorum中除了存储了-Root-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。此外，Zookeeper也避免了HMaster的单点问题
		B：HMaster；HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行，HMaster在功能上主要负责Table和Region的管理工作
			>>管理用户对Table的增、删、改、查操作
			>>管理HRegionServer的负载均衡，调整Region分布
			>>在Region Split后，负责新Region的分配
			>>在HRegionServer停机后，负责失效HRegionServer上的Regions迁移
		C：HRegionServer；HRegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块
			HRegionServer内部管理了一系列HRegion对象，每个HRegion对应了Table中的一个Region，HRegion中由多个HStore组成。每个HStore对应了Table中的一个Column Family存储，可以看出每个Column Family其实就是一个集中的存储单元，因此最好将具备共同IO特性的column放在一个Column Family中，这样最高效。
			HStore存储是HBase存储的核心了，其中由两部分组成，一部分是MemStore,一部分是StoreFiles。
			MemStore是Soretd MemoStore是Sorted Memory Buffer，用户写入的数据首先会放入MemStore,当MemStore满了以后会Flush成一个StoreFile（底层实现HFile），当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile，合并过程中会进行版本合并和数据删除，因此可以看出HBase其实只有增加数据，所有的更新和删除操作都是在后续的compact过程中进行的，这使得用户的写操作只要进入内存中就可以立即返回，保证了HBase I/O的高性能。
			当StoreFiles Compact后，会逐渐形成越来越大的StoreFile，当单个StoreFile大小超过一定阈值后，会触发Split操作，同时把当前Region Split成2个Region，父Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上，



			在理解了上述HStore的基本原理后，还必须了解一下HLog的功能，因为上述的HStore在系统正常工作的前提下没有问题的，但是在分布式系统环境中，无法避免系统出错或者宕机，因此一旦HRegionServer意外退出，MemStore中的内存数据将会丢失，这就需要引入HLog.
			每个HRegionServer中都有一个HLog对象，HLog是一个实现Write AheadLog的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中（HLog文件格式见后续），HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取到这些region的HRegionSeerver在load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog的数据到MemStore中，然后flush到StoreFiles，完成数据恢复

	（6）、存储格式
		HBase中所有数据文件都存储在Hadoop HDFS文件系统上，主要包括上述提出的文件两种文件类型
		A：HFile，HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile
		B：HLog File，HBase中WAL（write Ahead Log）的存储格式，物理上是Hadoop的Sequence File


5、Hbase自生整理文档

	（1）概述；HBase是一个构建在HDFS上的分布式列存储系统，是基于Google BigTable模型开发的典型的key/value系统，是Apache Hadoop生态系统中的重要一员主要用于海量结构化数据存储。和hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。
	（2）Hbase特点；
		1 大：一个表可以有数十亿行，上百万行
		2 无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列
		3 面向列：面向列（族）的存储和权限控制，列（族）独立检索
		4 稀疏：空（null）列并不占用存储空间，表可以设计的非常稀疏
		5 数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳
		6 数据类型单一：Hbase中的数据都是字符串，没有类型
	（3）Hbase数据模型
		RowKey:是byte array,是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要。
		Column Family:列簇，拥有一个名称（String），包含一个或者多个相关列
		Column：属于某一个columnfamily,familyName:columnName，每条记录可动态添加 
		Version Number：类型为Long，默认值是系统时间戳，可由用户自定义
		Value（Cell）：Byte array
		每个column family存储在HDFS上的一个单独文件中，空值不会被保存。Key和version number在每个column family中均有一份。HBase为每个值维护了多级索引，即：<key,column family,column name,timestamp>
	（4）物理存储；
		1 Table中所有行都按照rowkey的字典排序
		2 Table在行的方向上分割为多个Region
		3 Region按大小分割的，每个表开始只有一个region，随着数据增多，region不断增长，当增大到一个阈值的时候，region就会等分两个新的region，之后会有越来越多的region
		4 Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分不到不同RegionServer上resource\hbase\003.jpg
		5 Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个store又由一个memStore和0至多个StoreFile组成，StoreFile包含HFile；memStore存储在内存中，Store存储在HDFS上resource\hbase\004.jpg
	（5）HBase架构及基本组件
		1 Client：包含访问Hbase的接口，并维护cache来加快对Hbase的访问，比如region的位置信息
		2 Master：为Region server分配region；负责Region Server的负载均衡；发现失效的Region Server并重新分配其上大的region；管理用户对table的增删改查操作
		3 Region Server：Regionserver维护region，处理对这些region的IO请求；Regionserver负责切分在运行过程中变得过大的region
		4 Zookeeper作用：通过选举，保证任何时候，集群中只有一个master，master与RegionServers启动时会向zookeeper注册；存储所有Region的寻址入口；实时监控Region server的上线和下线信息。并实时通知给Master；存储HBase的schema和table元数据；默认情况下，HBase管理zookeeper实例，比如，启动或者停止zookeeper；zookeeper的引入使得Master不再是单点故障resource\hbase\006.jpg
	
	（6）Write-Ahead-Log（WAL）
		该机制用于数据的容错和恢复resource\hbase\007.jpg
		每个HRegionServer中都有一个HLog对象，HLog是一个实现Write Ahead Log的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中（HLog文件格式见后续），HLog文件定期会滚动出新的，并删除旧的文件（已持久到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore，然后flush到storeFile，完成数据恢复
		1 Master容错：zookeeper重新选择一个新的Master；无Master过程中，数据读取仍然照常进行；无master过程中，region切分、负载均衡等无法进行
		2 Region Server容错：定时向zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务进行分割并派送给新的RegionServer
		3 zookeeper容错：zookeeper是一个可靠地服务，一般配置3或5个zookeeper实例
		4 Region定位流程：resource\hbase\008.jpg
			A、寻找RegionServer；Zookeeper——>ROOT（单Region）——>.META——>用户表
			B、ROOT；表包含.MEAT,表所在的region列表，该表只会有一个Region；Zookeeper中记录了ROOT表的location
			C、.MEAT；表包含所有的用户空间region列表，以及RegionServer的服务器地址
	（7） Hbase使用场景
		大数据量存储，大数据量高并发操作；需要对苏剧随机读取操作；读写访问均是非常简单的操作
	（8）Hbase与HDFS对
		两者都具有良好的容错性的扩展性，都可以扩展到成百上千哥节点；HDFS适合批处理场景；不支持数据随机查找；不适合增量数据处理；不支持数据更新resource\hbase\009.jpg
	（9）Hbase 常用命令
		1、进入hbase shell console: hbase shell
		2、查看哪些表：list
		3、创建表：create <table>,{name=><family>,version =><version>} 例如，create ‘t1’,{name => ‘f1’,version =>2},{name => ‘f2’, version => 2}
		4、删除表：分两步，首先disable 然后 drop 例如，disable ‘t1’ , drop ‘t1’
		5、查看表结构：describe <name>
		6、修改表结构：修改表结构首先必须disable 然后 alter ‘t1’,{name=>‘f1’},{name=>‘f2’,method=>’delete’}
		7、分配权限：
			a)语法：grant <user> <permission> <table> <column family> <column qualified>
			b)权限用五个字母表示“RWXCA” READ(‘R’)、WRITE（‘W’）、EXEC（‘X’）,CREATE(‘C’)、ADMIN(‘A’)
			c)实例：grant ‘test’，‘RW’，‘t1’给用户’test’分配表t1有读写的权限
		8、查看权限：
			a)语法：user_permission <table>
			b)实例：user_permission ‘t1’
		9、收回权限
			a)语法：revoke <user> <table> <column family> <column qualifier>
			b)例子：revoke ‘test’,’t1’
		10、添加数据
			a)语法 put<table> , <rowkey> , <family:column> , <value> ,  <timestamp>
			b)例子：put ‘t1’,’rowkey001’,’f1:col1’,’value01’
		11、查询数据
			a)查询某行记录：get <table>,<rowkey>,[<family:column>,...]
			b)扫描表：scan <table> , {columns=>[<family:column>,...] , limit=>num}
			c)例如：scan ‘t1’,{limit=>5}
			d)查询表中的数据行数：count<table>, {interval => intervalNum, cache => cacheNum},其中interval设置多少行显示一次对应的rowkey,默认1000。Cache每次去取的缓存区大小，默认是10,调整该参数可提高查询速度
			e)例如：count ‘t1’,{interval => 100,cache => 500}
			f)删除某行中的某个列值：delete <table>,<rowkey>, <family:column>,<timestamp>
			g)删除行：deleteall <table>,<rowkey>,<family:column>, <timestamp>，可以不指定列名，删除整行数据
			h)例如：deleteall ‘t1’,’rowkey001’
			i)删除表中的所有数据：truncate <table>
		12、Region管理
			a)移动region: move ‘encodeRegionName’,‘serverName’其中encodeRegionName指的regionName后面的编码，ServerName指的是master-status的Region Servers
			b)开启/关闭region： balance_switch true|false
			手动split:split ‘regionName’,’splitKey’
		



