1、Hbase安装配置之伪分布式模式   http://blog.csdn.net/pdw2009/article/details/21261417

2、HBase安装配置（整合到hadoop）  http://blog.csdn.net/hguisu/article/details/7244413/

3、伪分布式集群环境hadoop、hbase、zookeeper搭建   http://blog.csdn.net/baolibin528/article/details/43768867

	（1）、配置hbase-env.sh:export JAVA_HOME=/usr/local/jdk;export HBASE_MANAGES_ZK=true
	（2）、修改hbase-site.xml
		<property>  
	      		<name>hbase.rootdir</name>  
	            	<value>hdfs://m:9000/hbase</value>  
		</property>  
		<property>  
			<name>hbase.cluster.distributed</name>  
			<value>true</value>  
		</property>  
		<property>  
			<name>hbase.zookeeper.quorum</name>  
			<value>m</value>  
		</property>  
		<property>  
			<name>dfs.replication</name>  
			<value>1</value>  
		</property>


4、zookeeper安装和配置（单机模式、伪集群方式、集群模式）  http://coolxing.iteye.com/blog/1871009

	伪集群方式：
	（1）、将zookeeper拷贝至3分。zookerrper0、zookeeper1、zookeeper2
	（2）、更改zook.cfg
		tickTime=2000    
		initLimit=5    
		syncLimit=2    
		dataDir=/Users/apple/zookeeper0/data    
		dataLogDir=/Users/apple/zookeeper0/logs    
		clientPort=2181  
		server.0=127.0.0.1:8880:7770    
		server.1=127.0.0.1:8881:7771    
		server.2=127.0.0.1:8882:7772
		注：另外两个需要修改dataDir、clientPort、dataLogDir
	（3）、在之前设置的dataDir中新建myid文件, 写入一个数字, 该数字表示这是第几号server. 该数字必须和zoo.cfg文件中的server.X中的X一一对应./Users/apple/zookeeper0/data/myid文件中写入0, /Users/apple/zookeeper1/data/myid文件中写入1, /Users/apple/zookeeper2/data/myid文件中写入2.
	（4）、启动zookeeper: zkService.sh start



4、Hbase简介  https://baike.baidu.com/item/HBase/7670213?fr=aladdin

	（1）、结构介绍
	（2）、模型
		A：逻辑模型，主要从用户角度考虑，如何使用hbase
		B：物理模型，主要从实现hbase角度来讨论
	（3）、访问接口
		A：Native Java API，最常规和高效的访问方式，适合hadoop MapReduce Job并行批处理Hbase表数据
		B：HBase Shell,HBase的命令行工具，最简单的接口，适合Hbase管理使用
		C：Thrift Gateway，利用Thrift序列化技术，支持c++、PHP、Python等多种语言，适合其他异构系统在线访问HBase表数据
		D：REST Gateway，支持Rest风格Http API访问HBase，解除了语言的限制
		E：Pig,可以使用Pig Latin流式编程语言来操作HBase中的数据，和Hive类似，本质最终也是编译成MapReduce Job来处理HBase表数据，适合做数据统计
		F：Hive，当前Hive的Release版本尚没有加入对HBase的支持，但在下一个版本Hive0.7.0中将会支持HBase，可以使用类似SQL语言来访问HBase
	（4）Table&Region
		当Table随着记录数不断增加变大后，会逐渐分裂成多份splits,成为regions，一个region由[startkey,endkey]表示，不同的region会被Master分配给相应的RegionServer进行管理
	（5）HBase系统架构
		ClientHBase Client使用HBase的RPC机制与HMaster和HRegionServer进行通信，对于管理类操作，Client与HMaster进行RPC，对于数据读写类操作，CLient和HRegionServer进行RPC
		A：zookeeper；zookeeper Quorum中除了存储了-Root-表的地址和HMaster的地址，HRegionServer也会把自己以Ephemeral方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的健康状态。此外，Zookeeper也避免了HMaster的单点问题
		B：HMaster；HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行，HMaster在功能上主要负责Table和Region的管理工作
			>>管理用户对Table的增、删、改、查操作
			>>管理HRegionServer的负载均衡，调整Region分布
			>>在Region Split后，负责新Region的分配
			>>在HRegionServer停机后，负责失效HRegionServer上的Regions迁移
		C：HRegionServer；HRegionServer主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBase中最核心的模块
			HRegionServer内部管理了一系列HRegion对象，每个HRegion对应了Table中的一个Region，HRegion中由多个HStore组成。每个HStore对应了Table中的一个Column Family存储，可以看出每个Column Family其实就是一个集中的存储单元，因此最好将具备共同IO特性的column放在一个Column Family中，这样最高效。
			HStore存储是HBase存储的核心了，其中由两部分组成，一部分是MemStore,一部分是StoreFiles。
			MemStore是Soretd MemoStore是Sorted Memory Buffer，用户写入的数据首先会放入MemStore,当MemStore满了以后会Flush成一个StoreFile（底层实现HFile），当StoreFile文件数量增长到一定阈值，会触发Compact合并操作，将多个StoreFiles合并成一个StoreFile，合并过程中会进行版本合并和数据删除，因此可以看出HBase其实只有增加数据，所有的更新和删除操作都是在后续的compact过程中进行的，这使得用户的写操作只要进入内存中就可以立即返回，保证了HBase I/O的高性能。
			当StoreFiles Compact后，会逐渐形成越来越大的StoreFile，当单个StoreFile大小超过一定阈值后，会触发Split操作，同时把当前Region Split成2个Region，父Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer上，使得原先1个Region的压力得以分流到2个Region上，



			在理解了上述HStore的基本原理后，还必须了解一下HLog的功能，因为上述的HStore在系统正常工作的前提下没有问题的，但是在分布式系统环境中，无法避免系统出错或者宕机，因此一旦HRegionServer意外退出，MemStore中的内存数据将会丢失，这就需要引入HLog.
			每个HRegionServer中都有一个HLog对象，HLog是一个实现Write AheadLog的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中（HLog文件格式见后续），HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取到这些region的HRegionSeerver在load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog的数据到MemStore中，然后flush到StoreFiles，完成数据恢复

	（6）、存储格式
		HBase中所有数据文件都存储在Hadoop HDFS文件系统上，主要包括上述提出的文件两种文件类型
		A：HFile，HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile
		B：HLog File，HBase中WAL（write Ahead Log）的存储格式，物理上是Hadoop的Sequence File

